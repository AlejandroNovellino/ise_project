{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pruebas para verificar el cumplimiento del objetivo específico C",
   "id": "a54b7d2dde7d82d7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuración Inicial y Autenticación",
   "id": "367cbec582d267f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import requests\n",
    "import threading\n",
    "import pandas as pd\n",
    "import random\n",
    "from dotenv import load_dotenv"
   ],
   "id": "d7cf4444228d575e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# function to get the access token\n",
    "def get_access_token(client_id, client_secret):\n",
    "    token_url = \"https://accounts.spotify.com/api/token\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "    }\n",
    "    data = {\n",
    "        \"grant_type\": \"client_credentials\",\n",
    "        \"client_id\": client_id,\n",
    "        \"client_secret\": client_secret\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(token_url, headers=headers, data=data)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        print('✅ Token loaded.')\n",
    "\n",
    "        return response.json()[\"access_token\"]\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error al obtener el token de acceso: {e}\")\n",
    "        return None"
   ],
   "id": "9c17fdf6ca081093",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# configuration\n",
    "load_dotenv()\n",
    "\n",
    "CLIENT_ID = os.environ.get('CLIENT_ID')\n",
    "CLIENT_SECRET = os.environ.get('CLIENT_SECRET')\n",
    "\n",
    "# get the access token\n",
    "ACCESS_TOKEN = get_access_token(CLIENT_ID, CLIENT_SECRET)\n",
    "if not ACCESS_TOKEN:\n",
    "    print(\"No se pudo obtener el token de acceso. Las pruebas no pueden continuar.\")\n",
    "    exit()\n",
    "\n",
    "HEADERS = {\n",
    "    \"Authorization\": f\"Bearer {ACCESS_TOKEN}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "ENDPOINTS_TO_TEST = [\n",
    "    # search\n",
    "    \"https://api.spotify.com/v1/search?q=remaster%2520track%3ADoxy%2520artist%3AMiles%2520Davis&type=album\",\n",
    "    # get album\n",
    "    \"https://api.spotify.com/v1/albums/4aawyAB9vmqN3uQ7FjRGTy\",\n",
    "    # get artist\n",
    "    \"https://api.spotify.com/v1/artists/0TnOYISbd1XYRBk9myaseg\",\n",
    "    # get playlist\n",
    "    \"https://api.spotify.com/v1/playlists/3cEYpjA9oz9GiPac4AsH4n\",\n",
    "    # get track\n",
    "    \"https://api.spotify.com/v1/tracks/11dFghVXANMlKmJXsNCbNl\",\n",
    "    # TODO Puedes añadir más endpoints aquí\n",
    "]\n",
    "\n",
    "# variables to save the results\n",
    "results_lock = threading.Lock()\n",
    "concurrent_test_results = []\n",
    "concurrent_test_individual_results = {\n",
    "    'user_ids': [],\n",
    "    'endpoints': [],\n",
    "    'status_codes': [],\n",
    "    'latencies': [],\n",
    "    'times': [] # Para registrar el tiempo en que se realizó la petición\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Funcion de concurrencia para realizar las pruebas",
   "id": "be0dfa8dbeec5c29"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def user_simulation_task(user_id, endpoint, headers, num_requests_per_user):\n",
    "    \"\"\"\n",
    "    Simula el comportamiento de un único usuario haciendo peticiones a un endpoint.\n",
    "    \"\"\"\n",
    "\n",
    "    user_results = {\n",
    "        'user_id': user_id,\n",
    "        'endpoint': endpoint,\n",
    "        'total_requests': 0,\n",
    "        'successful_requests': 0,\n",
    "        'error_4xx_requests': 0,\n",
    "        'error_5xx_requests': 0,\n",
    "        'total_response_time': 0,\n",
    "        'latencies': [], # Para registrar tiempos de respuesta individuales\n",
    "        'errors_occurred': [], # Para registrar códigos de error\n",
    "        'test_duration': 0\n",
    "    }\n",
    "\n",
    "    user_ids = []\n",
    "    endpoints = []\n",
    "    status_codes = []\n",
    "    latencies = []\n",
    "    times = []\n",
    "\n",
    "    # test info\n",
    "    test_start_time = time.time()\n",
    "    print(f\"✴️ Usuario {user_id} - Starting requests to {endpoint}. - Test started at {test_start_time}\")\n",
    "\n",
    "    # do requests for the given amount\n",
    "    for i in range(num_requests_per_user):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            # request\n",
    "            response = requests.get(endpoint, headers=headers)\n",
    "\n",
    "            # ☑️ save the data to study\n",
    "\n",
    "            #   save the whole test results\n",
    "            duration = time.time() - start_time\n",
    "            user_results['total_requests'] += 1\n",
    "            user_results['total_response_time'] += duration\n",
    "            user_results['latencies'].append(duration)\n",
    "            status_code = response.status_code\n",
    "\n",
    "            #   save the individual test results\n",
    "            user_ids.append(user_id)\n",
    "            endpoints.append(endpoint)\n",
    "            status_codes.append(status_code)\n",
    "            latencies.append(duration)\n",
    "            times.append(time.time()) # save the time in floating point\n",
    "\n",
    "            if 200 <= status_code < 300: # if request successful\n",
    "                user_results['successful_requests'] += 1\n",
    "\n",
    "            elif 400 <= status_code < 500: # if request of kind 4xx\n",
    "                user_results['error_4xx_requests'] += 1\n",
    "                user_results['errors_occurred'].append(status_code)\n",
    "\n",
    "                if status_code == 429: # if request of kind 429 (to many requests)\n",
    "                    print(f\"Usuario {user_id} - Alerta: Recibido 429 (Too Many Requests).\")\n",
    "\n",
    "                    #retry_after = response.headers.get('Retry-After')\n",
    "                    # if retry_after:\n",
    "                    #     wait_time = int(retry_after) + 1\n",
    "                    #     print(f\"Usuario {user_id} - Esperando {wait_time}s antes de reintentar.\")\n",
    "                    #     time.sleep(wait_time) # Esperar antes de la próxima petición\n",
    "\n",
    "            elif 500 <= status_code < 600:\n",
    "                user_results['error_5xx_requests'] += 1\n",
    "                user_results['errors_occurred'].append(status_code)\n",
    "                print(f\"Usuario {user_id} - Error 5xx ({status_code}) en {endpoint}.\")\n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "\n",
    "            user_results['total_requests'] += 1 # Contar también las peticiones con excepción\n",
    "            user_results['errors_occurred'].append(str(e)) # Registrar la excepción\n",
    "            print(f\"Usuario {user_id} - Excepción de red para {endpoint}: {e}\")\n",
    "\n",
    "    test_finish_time = time.time()\n",
    "    test_duration = test_finish_time - test_start_time\n",
    "\n",
    "    # save the test duration\n",
    "    user_results['test_duration'] = test_duration\n",
    "\n",
    "    print(f\"✅ User {user_id} - Finished requests to {endpoint}. - Test finished at {test_finish_time}. Duration: {test_duration:.2f}s\")\n",
    "\n",
    "    # add the results to the global results\n",
    "    with results_lock:\n",
    "        # save the whole test results\n",
    "        concurrent_test_results.append(user_results)\n",
    "        # save the individual test results\n",
    "        concurrent_test_individual_results['user_ids'].extend(user_ids)\n",
    "        concurrent_test_individual_results['endpoints'].extend(endpoints)\n",
    "        concurrent_test_individual_results['status_codes'].extend(status_codes)\n",
    "        concurrent_test_individual_results['latencies'].extend(latencies)\n",
    "        concurrent_test_individual_results['times'].extend(times)\n"
   ],
   "id": "46d568e2df1ea552",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Orquestacion de usuarios concurrentes",
   "id": "e4663bb0670ab640"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Simulamos multiples usuarios de forma concurrente para probar los endpoints de la API de Spotify.",
   "id": "3d83549517fd3ff3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def simulate_concurrent_users(num_users, num_requests_per_user, endpoints_to_test):\n",
    "    \"\"\"\n",
    "    Orquesta la simulación de múltiples usuarios concurrentes.\n",
    "\n",
    "    Args:\n",
    "        num_users (int): El número de usuarios a simular.\n",
    "        num_requests_per_user (int): El número de peticiones que cada usuario hará.\n",
    "        endpoints_to_test (list): Lista de endpoints a los que los usuarios harán peticiones.\n",
    "                                  Los usuarios se distribuirán entre estos endpoints.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\n--- Simulation started with {num_users} concurrent users ---\")\n",
    "    print(f\"Each user will do {num_requests_per_user} requests.\\n\")\n",
    "\n",
    "    threads = []\n",
    "\n",
    "    # create a thread for each user\n",
    "    endpoint_index = 0\n",
    "\n",
    "    for i in range(num_users):\n",
    "        # select the endpoint for the user\n",
    "        selected_endpoint = endpoints_to_test[endpoint_index % len(endpoints_to_test)]\n",
    "\n",
    "        # create the thread\n",
    "        thread = threading.Thread(\n",
    "            target=user_simulation_task,\n",
    "            args=(i + 1, selected_endpoint, HEADERS, num_requests_per_user)\n",
    "        )\n",
    "        threads.append(thread)\n",
    "        thread.start() # Inicia el hilo\n",
    "        endpoint_index += 1\n",
    "\n",
    "        # wait i little for the next thread\n",
    "        time.sleep(random.uniform(0.01, 0.1))\n",
    "\n",
    "    # wait to each thread to finish\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    print(\"\\n--- Simulation finished ---\")"
   ],
   "id": "9f404451e3b0736",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Objetivo C",
   "id": "be1b0d9e738d87c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Hacemos las pruebas base para cumplir con el objetivo A. Vamos a probar todos los endpoints que declaramos que son los servicios a estudiar, y vamos a tomar todas las mediciones para luego poder responder a las metricas establecidas.",
   "id": "12977731856ddcae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "simulate_concurrent_users(\n",
    "    num_users=30,\n",
    "    num_requests_per_user=30,\n",
    "    endpoints_to_test=ENDPOINTS_TO_TEST\n",
    ")"
   ],
   "id": "ccae18203aa72813",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Procesa los resultados",
   "id": "42166f87c696740f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def process_concurrent_results():\n",
    "    \"\"\"\n",
    "    Consolida y analiza los resultados de la simulación de usuarios concurrentes.\n",
    "    \"\"\"\n",
    "    if not concurrent_test_results:\n",
    "        print(\"No hay resultados para procesar de la simulación concurrente.\")\n",
    "        return\n",
    "\n",
    "    df_concurrent = pd.DataFrame(concurrent_test_results)\n",
    "    df_concurrent_2 = pd.DataFrame(concurrent_test_individual_results)\n",
    "\n",
    "    # global calculates\n",
    "    global_total_requests = df_concurrent['total_requests'].sum()\n",
    "    global_successful_requests = df_concurrent['successful_requests'].sum()\n",
    "    global_error_4xx_requests = df_concurrent['error_4xx_requests'].sum()\n",
    "    global_error_5xx_requests = df_concurrent['error_5xx_requests'].sum()\n",
    "    global_success_rate = (global_successful_requests / global_total_requests) * 100 if global_total_requests > 0 else 0\n",
    "    global_error_4xx_rate = (global_error_4xx_requests / global_total_requests) * 100 if global_total_requests > 0 else 0\n",
    "    global_error_5xx_rate = (global_error_5xx_requests / global_total_requests) * 100 if global_total_requests > 0 else 0\n",
    "\n",
    "    # global results\n",
    "    print(\"\\n--- Resumen General de la Simulación Concurrente ---\")\n",
    "    print(f\"Total de usuarios simulados: {len(df_concurrent)}\")\n",
    "    print(f\"Peticiones totales realizadas: {df_concurrent['total_requests'].sum()}\")\n",
    "    print(f\"Peticiones exitosas totales: {df_concurrent['successful_requests'].sum()}\")\n",
    "    print(f\"Errores 4xx totales: {df_concurrent['error_4xx_requests'].sum()}\")\n",
    "    print(f\"Errores 5xx totales: {df_concurrent['error_5xx_requests'].sum()}\")\n",
    "    print(f\"Tasa de éxito global: {global_success_rate:.2f}%\")\n",
    "    print(f\"Tasa de error 4xx global: {global_error_4xx_rate:.2f}%\")\n",
    "    print(f\"Tasa de error 5xx global: {global_error_5xx_rate:.2f}%\")\n",
    "\n",
    "    # analysis by endpoint\n",
    "    agg_by_endpoint = df_concurrent.groupby('endpoint').agg(\n",
    "        total_requests=('total_requests', 'sum'),\n",
    "        successful_requests=('successful_requests', 'sum'),\n",
    "        error_4xx_requests=('error_4xx_requests', 'sum'),\n",
    "        error_5xx_requests=('error_5xx_requests', 'sum'),\n",
    "        avg_latency=('latencies', lambda x: pd.Series([item for sublist in x for item in sublist]).mean()),\n",
    "        num_users=('user_id', 'nunique')\n",
    "    ).reset_index()\n",
    "\n",
    "    agg_by_endpoint['success_rate'] = (agg_by_endpoint['successful_requests'] / agg_by_endpoint['total_requests']) * 100\n",
    "    agg_by_endpoint['error_4xx_rate'] = (agg_by_endpoint['error_4xx_requests'] / agg_by_endpoint['total_requests']) * 100\n",
    "    agg_by_endpoint['error_5xx_rate'] = (agg_by_endpoint['error_5xx_requests'] / agg_by_endpoint['total_requests']) * 100\n",
    "\n",
    "    return df_concurrent, df_concurrent_2, agg_by_endpoint"
   ],
   "id": "a5a0bdd2ac76db1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# process the results\n",
    "df_global_results, df_individual_results, df_by_endpoint = process_concurrent_results()"
   ],
   "id": "9ff78ba770d2ce58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('\\nGlobal results\\n')\n",
    "df_global_results"
   ],
   "id": "34aa4ef1f4142cba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('\\nIndividual results\\n')\n",
    "df_individual_results"
   ],
   "id": "f59b7e02ae07892b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('\\nResults by endpoint\\n')\n",
    "df_by_endpoint"
   ],
   "id": "3ac169eb09673165",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Guardamos los resultados base",
   "id": "3bbc99ad8a414e67"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_global_results.to_csv('./files/obj-C/global_results.csv', index=False)\n",
    "df_individual_results.to_csv('./files/obj-C/individual_results.csv', index=False)\n",
    "df_by_endpoint.to_csv('./files/obj-C/endpoints_results.csv', index=False)"
   ],
   "id": "3cd9b3c9d3df5b5b",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
